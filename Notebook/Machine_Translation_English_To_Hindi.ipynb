{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
        "data = pd.read_parquet(\"hf://datasets/cfilt/iitb-english-hindi/\" + splits[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R74hCdZwe-Mz",
        "outputId": "d5e5b823-528c-4a1c-eb17-9206c6cdb786"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHhnr4FHiyEY",
        "outputId": "d4cab203-28ed-4bb8-d2ce-c753833f5869"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               translation\n",
            "0        {'en': 'Give your application an accessibility...\n",
            "1        {'en': 'Accerciser Accessibility Explorer', 'h...\n",
            "2        {'en': 'The default plugin layout for the bott...\n",
            "3        {'en': 'The default plugin layout for the top ...\n",
            "4        {'en': 'A list of plugins that are disabled by...\n",
            "...                                                    ...\n",
            "1659078  {'en': 'The Prime Minister, Shri Narendra Modi...\n",
            "1659079  {'en': 'In a tweet, the Prime Minister said, c...\n",
            "1659080  {'en': 'I also congratulate all those who took...\n",
            "1659081  {'en': 'The NDA family will work together for ...\n",
            "1659082  {'en': 'I assure all possible support from the...\n",
            "\n",
            "[1659083 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print((data.iloc[i]['translation']['en']))\n",
        "    print((data.iloc[i]['translation']['hi']))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25EApXZYiL4Z",
        "outputId": "0d77c183-c5f7-471e-b10a-6b98374ce05c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give your application an accessibility workout\n",
            "अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
            "\n",
            "\n",
            "Accerciser Accessibility Explorer\n",
            "एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
            "\n",
            "\n",
            "The default plugin layout for the bottom panel\n",
            "निचले पटल के लिए डिफोल्ट प्लग-इन खाका\n",
            "\n",
            "\n",
            "The default plugin layout for the top panel\n",
            "ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका\n",
            "\n",
            "\n",
            "A list of plugins that are disabled by default\n",
            "उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है\n",
            "\n",
            "\n",
            "Highlight duration\n",
            "अवधि को हाइलाइट रकें\n",
            "\n",
            "\n",
            "The duration of the highlight box when selecting accessible nodes\n",
            "पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि\n",
            "\n",
            "\n",
            "Highlight border color\n",
            "सीमांत (बोर्डर) के रंग को हाइलाइट करें\n",
            "\n",
            "\n",
            "The color and opacity of the highlight border.\n",
            "हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। \n",
            "\n",
            "\n",
            "Highlight fill color\n",
            "भराई के रंग को हाइलाइट करें\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame setup (Replace this with your actual data loading)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#  Since Data is Very Large We are taking only first 10,000 rows to perform\n",
        "df=df[:10000]\n",
        "\n",
        "df['english_sentence'] = df['translation'].apply(lambda x: x.get('en', ''))\n",
        "df['hindi_sentence'] = df['translation'].apply(lambda x: x.get('hi', ''))\n",
        "\n",
        "df = df.drop(columns=['translation'])\n",
        "\n",
        "df.to_csv('LimitedHindiToEngilsh.csv', index=False)\n",
        "\n",
        "print(df)\n",
        "print(\"Dataset successfully saved to 'LimitedHindiToEngilsh.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzJ5zA0Fg-3i",
        "outputId": "a6a00b65-fd49-4057-95e8-26bf5a9597ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    english_sentence  \\\n",
            "0     Give your application an accessibility workout   \n",
            "1                  Accerciser Accessibility Explorer   \n",
            "2     The default plugin layout for the bottom panel   \n",
            "3        The default plugin layout for the top panel   \n",
            "4     A list of plugins that are disabled by default   \n",
            "...                                              ...   \n",
            "9995                                      Properties   \n",
            "9996                                         Signals   \n",
            "9997                           Author Email Address:   \n",
            "9998                                        License:   \n",
            "9999                                  Add to Project   \n",
            "\n",
            "                                         hindi_sentence  \n",
            "0       अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें  \n",
            "1                       एक्सेर्साइसर पहुंचनीयता अन्वेषक  \n",
            "2                 निचले पटल के लिए डिफोल्ट प्लग-इन खाका  \n",
            "3                  ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका  \n",
            "4     उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...  \n",
            "...                                                 ...  \n",
            "9995                                                गुण  \n",
            "9996                                             सिग्नल  \n",
            "9997                                         ई-मेल पताः  \n",
            "9998                                           लाइसेंसः  \n",
            "9999                                परियोजना में जोड़ें  \n",
            "\n",
            "[10000 rows x 2 columns]\n",
            "Dataset successfully saved to 'translations.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KvXOtJ_2TLh7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "english_sentences = df['english_sentence'].tolist()\n",
        "hindi_sentences = df['hindi_sentence'].tolist()\n",
        "\n",
        "def tokenize_and_pad(sentences, max_len):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "    return tokenizer, padded_sequences\n",
        "\n",
        "max_eng_len = max(len(seq) for seq in english_sentences)\n",
        "max_hin_len = max(len(seq) for seq in hindi_sentences)\n",
        "\n",
        "eng_tokenizer, eng_sequences = tokenize_and_pad(english_sentences, max_eng_len)\n",
        "hin_tokenizer, hin_sequences = tokenize_and_pad(hindi_sentences, max_hin_len)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(eng_sequences, hin_sequences, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, RepeatVector, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "embedding_dim = 128  # previously -> 256\n",
        "hidden_units = 128\n",
        "vocab_size_eng = len(eng_tokenizer.word_index) + 1\n",
        "vocab_size_hin = len(hin_tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size_eng, embedding_dim, input_length=max_eng_len),\n",
        "    Bidirectional(LSTM(hidden_units, return_sequences=False, dropout=0.3)),\n",
        "    RepeatVector(max_hin_len),\n",
        "    Bidirectional(LSTM(hidden_units, return_sequences=True, dropout=0.3)),\n",
        "    TimeDistributed(Dense(vocab_size_hin, activation='softmax'))\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch % 5 == 0 and epoch != 0:\n",
        "        lr = lr * 0.9\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train.reshape(*y_train.shape, 1),\n",
        "    epochs=5,   #previously -> 20\n",
        "    batch_size=200,#previously -> 64\n",
        "    validation_data=(X_test, y_test.reshape(*y_test.shape, 1)),\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlRduWzep4ve",
        "outputId": "160e7e6e-959a-4471-f0b2-1858a03a1795"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "40/40 [==============================] - 119s 3s/step - loss: 7.2268 - accuracy: 0.8730 - val_loss: 5.5350 - val_accuracy: 0.9885 - lr: 1.0000e-04\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 109s 3s/step - loss: 2.2997 - accuracy: 0.9882 - val_loss: 0.4560 - val_accuracy: 0.9885 - lr: 1.0000e-04\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 108s 3s/step - loss: 0.2665 - accuracy: 0.9882 - val_loss: 0.1824 - val_accuracy: 0.9885 - lr: 1.0000e-04\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 109s 3s/step - loss: 0.1692 - accuracy: 0.9882 - val_loss: 0.1535 - val_accuracy: 0.9885 - lr: 1.0000e-04\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 108s 3s/step - loss: 0.1498 - accuracy: 0.9882 - val_loss: 0.1414 - val_accuracy: 0.9885 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb82448e3e0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test.reshape(*y_test.shape, 1))\n",
        "\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuGBXsRi7wCF",
        "outputId": "58165539-f838-44a6-fbe4-b7327d5d0cbb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 17s 248ms/step - loss: 0.1414 - accuracy: 0.9885\n",
            "Test Loss: 0.1413617730140686\n",
            "Test Accuracy: 0.9884709119796753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the prediction\n",
        "predicted_sequence = model.predict(new_sentence_padded)\n",
        "predicted_indices = np.argmax(predicted_sequence, axis=-1)\n",
        "\n",
        "# Print the predicted token indices\n",
        "print(f'Predicted Indices: {predicted_indices[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ABOy1Tb8Em3",
        "outputId": "d01fc7b6-274a-48df-f7bb-f1100e4fe2f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "Predicted Indices: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Hindi words corresponding to the predicted indices\n",
        "translated_sentence = ' '.join([hin_tokenizer.index_word.get(idx, '[UNK]') for idx in predicted_indices[0]])\n",
        "print(f'Translated Hindi Sentence: {translated_sentence}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqzPTH3R8WtM",
        "outputId": "0306e3f6-eb32-4e8c-ae8e-636dab999af0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Hindi Sentence: [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad the new English sentence correctly\n",
        "new_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "new_sentence_tokenized = eng_tokenizer.texts_to_sequences([new_sentence])\n",
        "\n",
        "# Make sure padding length matches the maximum input length\n",
        "new_sentence_padded = pad_sequences(new_sentence_tokenized, maxlen=max_eng_len, padding='post')\n",
        "\n",
        "print(f'Padded Input Sentence: {new_sentence_padded}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M5F3aNo8frU",
        "outputId": "eda1a2aa-c038-47ed-9dff-bd32a93acee1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded Input Sentence: [[   1  511 1200    1  848    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few token-to-word mappings\n",
        "for i in range(1, 10):\n",
        "    print(f\"Token {i}: {hin_tokenizer.index_word.get(i, '[UNK]')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAJ3_RaG8hun",
        "outputId": "c53999fb-8bab-48ec-b266-ef30eeae99aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 1: का\n",
            "Token 2: को\n",
            "Token 3: के\n",
            "Token 4: करें\n",
            "Token 5: में\n",
            "Token 6: 2\n",
            "Token 7: एक\n",
            "Token 8: a\n",
            "Token 9: की\n"
          ]
        }
      ]
    }
  ]
}